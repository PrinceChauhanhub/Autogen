{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff3d42b",
   "metadata": {},
   "source": [
    "# Team Operations: Reset, Stop, Resume and Abort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d490dec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model = \"meta-llama/llama-3.3-70b-instruct:free\",\n",
    "    api_key=api_key,\n",
    "    model_info={\n",
    "        \"family\":\"meta-llama\",\n",
    "        \"vision\" : True,\n",
    "        \"function_calling\":True,\n",
    "        \"json_output\":False,\n",
    "    }\n",
    ")\n",
    "\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "\n",
    "client = OllamaChatCompletionClient(model=\"gemma2:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9881688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "add_1_agent_first = AssistantAgent(\n",
    "    name = \"add_1_agent_first\",\n",
    "    model_client=client,\n",
    "    system_message=\"Add 1 to the number and just give out resultant number. Start with 0 if nothing is provided.\"\n",
    ")\n",
    "\n",
    "add_1_agent_second = AssistantAgent(\n",
    "    name = \"add_1_agent_second\",\n",
    "    model_client=client,\n",
    "    system_message=\"Add 1 to the number and just give out resultant number.\"\n",
    ")\n",
    "\n",
    "add_1_agent_third = AssistantAgent(\n",
    "    name = \"add_1_agent_third\",\n",
    "    model_client=client,\n",
    "    system_message=\"Add 1 to the number and just give out resultant number.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e128fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [add_1_agent_first, add_1_agent_second, add_1_agent_third],\n",
    "    max_turns= 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d2e4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "First number 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "1 \n",
      "\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "1 \n",
      "\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "2 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='bb5e7f56-a77f-4af9-889a-cfa16c0e10cc', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 17, 51, 714776, tzinfo=datetime.timezone.utc), content='First number 0', type='TextMessage'), TextMessage(id='8be6837d-acee-46ec-bf17-bd1a06f187eb', source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=35, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 10, 846090, tzinfo=datetime.timezone.utc), content='1 \\n', type='TextMessage'), TextMessage(id='069476ed-cd5e-4751-9521-190f7672ee76', source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=30, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 13, 214682, tzinfo=datetime.timezone.utc), content='1 \\n', type='TextMessage'), TextMessage(id='608e2c0a-e0a0-455c-b25e-8f96e6e172ec', source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=33, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 15, 187435, tzinfo=datetime.timezone.utc), content='2 \\n', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(team.run_stream(task =\"First number 0\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b164ca",
   "metadata": {},
   "source": [
    "# Resuming a Team\n",
    "\n",
    "teams are stateful and maintains the conversation history and context after each run, unless you reset the team.\n",
    "\n",
    "We can resume a team to continue from where it left off by calling the run() or run_stream() method without a raw task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8b911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "3  \n",
      "\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "4 \n",
      "\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "5 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='386d6516-8cd1-42cf-8d2e-b65d52a9d29c', source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=54, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 23, 172406, tzinfo=datetime.timezone.utc), content='3  \\n', type='TextMessage'), TextMessage(id='47d1017d-58ae-4862-921a-10deb8e9cd54', source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=49, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 27, 838172, tzinfo=datetime.timezone.utc), content='4 \\n', type='TextMessage'), TextMessage(id='2ca8e16f-96bd-49bf-8568-29bd9af9ae31', source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=52, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 31, 939521, tzinfo=datetime.timezone.utc), content='5 \\n', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ye previous number ke aage se continue krega add krna\n",
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a98073c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What was the larget number you got in result\n",
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The largest result I got was 5.  \n",
      "\n",
      "Let me know if you'd like to continue playing! üòä \n",
      "\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "Okay, let's keep going! üòÑ\n",
      "\n",
      "Give me the next number.   \n",
      "\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "You're right! My apologies, I seem to have gotten confused. \n",
      "\n",
      "I'll keep track better this time.  Please give me the next number. üëç \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='94673bf0-0605-4f31-b097-67ed856094fe', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 31, 957893, tzinfo=datetime.timezone.utc), content='What was the larget number you got in result', type='TextMessage'), TextMessage(id='e4bdd492-04c2-4a80-9e76-0d36922b91e5', source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=83, completion_tokens=27), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 43, 910823, tzinfo=datetime.timezone.utc), content=\"The largest result I got was 5.  \\n\\nLet me know if you'd like to continue playing! üòä \\n\", type='TextMessage'), TextMessage(id='9e0f612b-fc4a-4da7-8665-5b7ddca1bad6', source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=102, completion_tokens=19), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 18, 56, 421028, tzinfo=datetime.timezone.utc), content=\"Okay, let's keep going! üòÑ\\n\\nGive me the next number.   \\n\", type='TextMessage'), TextMessage(id='6755b023-cebd-4738-aab8-10235e773c3d', source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=120, completion_tokens=38), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 19, 13, 251869, tzinfo=datetime.timezone.utc), content=\"You're right! My apologies, I seem to have gotten confused. \\n\\nI'll keep track better this time.  Please give me the next number. üëç \\n\", type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream(task=\"What was the larget number you got in result\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d754b0fc",
   "metadata": {},
   "source": [
    "## Reset our team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "587ae5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "await team.reset()    ## intrnally call on_reset() to reset all agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d76dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "0 \n",
      "\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "1 \n",
      "\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "2  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(id='c97e2e42-ed7a-4bb2-9530-4e815cc9aa05', source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=32, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 20, 46, 863818, tzinfo=datetime.timezone.utc), content='0 \\n', type='TextMessage'), TextMessage(id='c40a0f3d-7eb5-442f-b16d-c9923202595a', source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=26, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 20, 48, 891182, tzinfo=datetime.timezone.utc), content='1 \\n', type='TextMessage'), TextMessage(id='e86516fa-a977-4234-95fa-08beec6e2259', source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=29, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 10, 7, 8, 20, 50, 985870, tzinfo=datetime.timezone.utc), content='2  \\n', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a334e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
