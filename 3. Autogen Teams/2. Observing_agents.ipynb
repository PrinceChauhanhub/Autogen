{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54949843",
   "metadata": {},
   "source": [
    "# Observe a Running team in AutoGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3832bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py:453: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model = \"openai/gpt-oss-20b:free\",\n",
    "    api_key=api_key,\n",
    "    model_info={\n",
    "        \"family\":\"openai\",\n",
    "        \"vision\" : True,\n",
    "        \"function_calling\":True,\n",
    "        \"json_output\":False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b1af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_agent = AssistantAgent(\n",
    "    name ='plot_agent',\n",
    "    model_client=model_client,\n",
    "    system_message=\"you create engaging plots for stories. Focus on the knight's journey. complete it in 10 words\"\n",
    ")\n",
    "\n",
    "character_agent = AssistantAgent(\n",
    "    name =\"character_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You develop Characters. Describe the knight and the Dragon in details, including their motivations and backgrounds. complete it in 10 words\"\n",
    ")\n",
    "\n",
    "ending_agent = AssistantAgent(\n",
    "    name=\"ending_writer\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You write engaging endings. Conclude the story with a twist. complete it in 10 words.\"\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e715b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [ plot_agent, character_agent, ending_agent],\n",
    "    max_turns= 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f25ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# async for msg in team.run_stream(task = \"Write a lovely poem on the spring season\"):\n",
    "#     print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a013d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='8ab8b944-b434-4d92-bd60-bec1c7ef3acc' source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 10, 6, 12, 56, 52, 727277, tzinfo=datetime.timezone.utc) content='Write a lovely poem on the spring season' type='TextMessage'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py:1107: UserWarning: Resolved model mismatch: openai/gpt-oss-20b:free != None. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to None to enhance token/cost estimation and suppress this warning.\n",
      "  model_result = await model_client.create(\n",
      "Error processing publish message for plot_agent_860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5/860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5\n",
      "Traceback (most recent call last):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 133, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 723, in create\n",
      "    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]\n",
      "                                                                        ~~~~~~~~~~~~~~^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Error processing publish message for character_agent_860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5/860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5\n",
      "Traceback (most recent call last):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 195, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
      "Error processing publish message for ending_writer_860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5/860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5\n",
      "Traceback (most recent call last):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 195, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TypeError: 'NoneType' object is not subscriptable\nTraceback:\nTraceback (most recent call last):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 133, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 723, in create\n    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]\n                                                                        ~~~~~~~~~~~~~~^^^\n\nTypeError: 'NoneType' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_agentchat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TaskResult\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m team.run_stream(task = \u001b[33m\"\u001b[39m\u001b[33mWrite a lovely poem on the spring season\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(msg, TaskResult):\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStop Reason: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg.stop_reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:554\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    552\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    555\u001b[39m     stop_reason = message.message.content\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: TypeError: 'NoneType' object is not subscriptable\nTraceback:\nTraceback (most recent call last):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 133, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 723, in create\n    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]\n                                                                        ~~~~~~~~~~~~~~^^^\n\nTypeError: 'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.base import TaskResult\n",
    "\n",
    "async for msg in team.run_stream(task = \"Write a lovely poem on the spring season\"):\n",
    "    if isinstance(msg, TaskResult):\n",
    "        print(f\"Stop Reason: {msg.stop_reason}\")\n",
    "    else:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b051f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "write a poem on the spring season\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py:1107: UserWarning: Resolved model mismatch: openai/gpt-oss-20b:free != None. Model mapping in autogen_ext.models.openai may be incorrect. Set the model to None to enhance token/cost estimation and suppress this warning.\n",
      "  model_result = await model_client.create(\n",
      "Error processing publish message for character_agent_860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5/860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5\n",
      "Traceback (most recent call last):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 133, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 723, in create\n",
      "    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]\n",
      "                                                                        ~~~~~~~~~~~~~~^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "Error processing publish message for plot_agent_860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5/860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5\n",
      "Traceback (most recent call last):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 195, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
      "Error processing publish message for ending_writer_860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5/860df0c4-4ffa-4f0e-ba49-f56e38a9f1c5\n",
      "Traceback (most recent call last):\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 195, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "TypeError: 'NoneType' object is not subscriptable\nTraceback:\nTraceback (most recent call last):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 133, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 723, in create\n    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]\n                                                                        ~~~~~~~~~~~~~~^^^\n\nTypeError: 'NoneType' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_agentchat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mui\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Console\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Console(team.run_stream(task = \u001b[33m\"\u001b[39m\u001b[33mwrite a poem on the spring season\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\ui\\_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    113\u001b[39m last_processed: Optional[T] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    119\u001b[39m         duration = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mx:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:554\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    552\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    555\u001b[39m     stop_reason = message.message.content\n\u001b[32m    556\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: TypeError: 'NoneType' object is not subscriptable\nTraceback:\nTraceback (most recent call last):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 133, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"x:\\Autogen\\autogen-env\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 723, in create\n    choice: Union[ParsedChoice[Any], ParsedChoice[BaseModel], Choice] = result.choices[0]\n                                                                        ~~~~~~~~~~~~~~^^^\n\nTypeError: 'NoneType' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(team.run_stream(task = \"write a poem on the spring season\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38f4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
